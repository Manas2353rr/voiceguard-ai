# ğŸ™ï¸ VoiceGuard AI

**Real-time Deepfake Voice Detection System**

VoiceGuard AI is a machine learning-powered web application that detects deepfake and synthetic voice recordings in real-time. Built with FastAPI and React, it uses advanced audio feature extraction and Random Forest classification to distinguish between authentic and AI-generated voices.

---

## âœ¨ Features

- ğŸ¤ **Real-time Audio Recording** - Record audio directly in your browser
- ğŸ“ **File Upload** - Upload WAV audio files for analysis
- ğŸ¤– **ML-Powered Detection** - Advanced machine learning model for accurate detection
- ğŸ“Š **Confidence Scores** - Get detailed confidence metrics for each prediction
- ğŸ¨ **Modern UI** - Clean, responsive user interface
- âš¡ **Fast API** - Lightning-fast backend powered by FastAPI
- ğŸŒ **Cloud Deployed** - Ready-to-use deployed backend

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  FastAPI Backend â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  ML Model (RF)  â”‚
â”‚   (Port 3000)    â”‚         â”‚   (Port 10000)   â”‚         â”‚  (Pickle File)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                            â”‚
         â”‚                            â”‚
    Audio Input                  Feature Extraction
    (Record/Upload)              (MFCC, ZCR, etc.)
```

### Components

1. **Frontend (React)**: User interface for recording/uploading audio and displaying results
2. **Backend (FastAPI)**: REST API that processes audio files and returns predictions
3. **ML Model**: Pre-trained Random Forest classifier for voice authenticity detection

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Uvicorn** - ASGI server
- **Librosa** - Audio feature extraction
- **Scikit-learn** - Machine learning model
- **NumPy** - Numerical computations
- **Joblib** - Model serialization

### Frontend
- **React 19.2.3** - UI framework
- **React Scripts** - Build tooling
- **MediaRecorder API** - Browser audio recording

### Machine Learning
- **Random Forest Classifier** - 200 estimators
- **Audio Features**: MFCC, Delta MFCC, Zero Crossing Rate, Spectral Centroid

---

## ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Node.js 14+** and **npm**
- **Audio files** in WAV format

---

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd "VoiceGaurd AI"
```

### 2. Backend Setup

```bash
# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
cd voiceguard-ui
npm install
```

---

## ğŸ¯ Usage

### Running the Backend

```bash
# From project root
uvicorn scripts.app:app --host 0.0.0.0 --port 10000 --reload
```

The API will be available at `http://localhost:10000`

### Running the Frontend

```bash
# From voiceguard-ui directory
cd voiceguard-ui
npm start
```

The frontend will be available at `http://localhost:3000`

### Using the Application

1. **Record Audio**: Click "ğŸ¤ Start Recording" to record audio directly in your browser
2. **Upload Audio**: Click "Choose File" to upload a WAV audio file
3. **Analyze**: Click "Analyze Voice" to get the prediction
4. **View Results**: See the prediction (REAL/FAKE) with confidence score

---

## ğŸ“¡ API Documentation

### Endpoint: `POST /predict`

Analyzes an audio file and returns a prediction.

**Request:**
- **Method**: POST
- **Content-Type**: multipart/form-data
- **Body**: 
  - `file`: Audio file (WAV format)

**Response:**
```json
{
  "prediction": "REAL" | "FAKE",
  "confidence": 0.95
}
```

**Example using cURL:**
```bash
curl -X POST "http://localhost:10000/predict" \
  -F "file=@audio_sample.wav"
```

**Example using Python:**
```python
import requests

url = "http://localhost:10000/predict"
files = {"file": open("audio_sample.wav", "rb")}
response = requests.post(url, files=files)
print(response.json())
```

---

## ğŸ§  Model Training

### Preparing the Dataset

1. Organize your audio files:
   ```
   data/
   â”œâ”€â”€ real/    # Authentic voice samples (.wav)
   â””â”€â”€ fake/    # Deepfake/synthetic voice samples (.wav)
   ```

2. Convert FLAC to WAV (if needed):
   ```bash
   python scripts/convert_flac_to_wav.py
   ```

### Training the Model

```bash
python scripts/train_model.py
```

This will:
- Load audio files from `data/real/` and `data/fake/`
- Extract features from each file
- Train a Random Forest classifier
- Evaluate the model and save it to `models/voiceguard_model.pkl`

### Feature Extraction

The model uses the following audio features:
- **MFCC (20 coefficients)**: Mel-frequency cepstral coefficients
- **Delta MFCC**: First-order derivatives of MFCC
- **Zero Crossing Rate**: Rate of sign changes in audio signal
- **Spectral Centroid**: Center of mass of the spectrum

---

## ğŸ“ Project Structure

```
VoiceGuard AI/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ app.py                    # FastAPI backend server
â”‚   â”œâ”€â”€ feature_extraction.py     # Audio feature extraction
â”‚   â”œâ”€â”€ train_model.py            # Model training script
â”‚   â”œâ”€â”€ prepare_dataset.py        # Dataset loader
â”‚   â”œâ”€â”€ convert_flac_to_wav.py   # Audio format converter
â”‚   â”œâ”€â”€ test_audio.py            # Audio testing utilities
â”‚   â””â”€â”€ visualize_mfcc.py        # MFCC visualization
â”œâ”€â”€ models/
â”‚   â””â”€â”€ voiceguard_model.pkl     # Trained model (pre-trained)
â”œâ”€â”€ voiceguard-ui/               # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js               # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css              # Component styles
â”‚   â”‚   â””â”€â”€ index.js             # React entry point
â”‚   â”œâ”€â”€ public/                  # Static assets
â”‚   â””â”€â”€ package.json             # Frontend dependencies
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ render.yaml                  # Render deployment config
â”œâ”€â”€ .gitignore                   # Git ignore rules
â””â”€â”€ README.md                    # This file
```

---

## ğŸš¢ Deployment

### Backend Deployment (Render)

The project includes a `render.yaml` configuration for easy deployment on Render:

```yaml
services:
  - type: web
    name: voiceguard-backend
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn scripts.app:app --host 0.0.0.0 --port 10000
```

**Steps:**
1. Push code to GitHub
2. Connect repository to Render
3. Render will automatically detect `render.yaml` and deploy

### Frontend Deployment

Build the React app for production:

```bash
cd voiceguard-ui
npm run build
```

Deploy the `build/` folder to any static hosting service:
- **Vercel**: `vercel --prod`
- **Netlify**: Drag and drop `build/` folder
- **GitHub Pages**: Follow React deployment guide

**Important**: Update the API URL in `voiceguard-ui/src/App.js` to point to your deployed backend.

---

## ğŸ”§ Configuration

### Backend Configuration

- **Port**: Default 10000 (configurable in `render.yaml` or startup command)
- **CORS**: Currently allows all origins (`*`) - restrict for production
- **Model Path**: `models/voiceguard_model.pkl` (relative to `scripts/`)

### Frontend Configuration

Update the API URL in `voiceguard-ui/src/App.js`:

```javascript
const API_URL = "https://your-backend-url.com/predict";
```

---

## ğŸ§ª Testing

### Test Audio Processing

```bash
python scripts/test_audio.py
```

### Visualize MFCC Features

```bash
python scripts/visualize_mfcc.py
```

---

## ğŸ“Š Model Performance

The Random Forest classifier is trained with:
- **Algorithm**: Random Forest
- **Estimators**: 200 trees
- **Train/Test Split**: 80/20
- **Stratified**: Yes (maintains class balance)

Model evaluation metrics are displayed during training.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ› Known Issues

- API URL in frontend has double slash (`//predict`) - should be fixed to `/predict`
- Temporary audio files are saved in `scripts/` directory - consider cleanup mechanism
- CORS is set to allow all origins - should be restricted in production

---

## ğŸ”® Future Enhancements

- [ ] Support for multiple audio formats (MP3, FLAC, etc.)
- [ ] Real-time streaming audio analysis
- [ ] Batch file processing
- [ ] User authentication and history
- [ ] Advanced visualization of audio features
- [ ] Model versioning and A/B testing
- [ ] Docker containerization
- [ ] CI/CD pipeline setup

---

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on GitHub.

---

## ğŸ™ Acknowledgments

- **Librosa** - Audio analysis library
- **Scikit-learn** - Machine learning framework
- **FastAPI** - Modern web framework
- **React** - UI framework

---

**Made with â¤ï¸ for detecting deepfake voices**
